{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ext_workspace/yuzijian2/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "from pointcept.engines.defaults import (\n",
    "    default_argument_parser,\n",
    "    default_config_parser,\n",
    "    default_setup,\n",
    ")\n",
    "from pointcept.datasets import build_dataset_iseg, collate_fn_iseg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. config\n",
    "pointcept 里加载 cfg 的流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config_file='configs/scannet/iseg-agile3d-v1m1.py', dist_url='auto', machine_rank=0, num_gpus=1, num_machines=1, options={'save_path': 'exp/test/data_loader'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = default_argument_parser().parse_args('')\n",
    "args.config_file = 'configs/scannet/iseg-agile3d-v1m1.py'\n",
    "args.options = {'save_path': 'exp/test/datasets_dataloader'}        # exp下只能两层，不然报错\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: configs/scannet/iseg-agile3d-v1m1.py): {'weight': None, 'resume': False, 'evaluate': True, 'test_only': False, 'seed': 25924780, 'save_path': 'exp/test/data_loader', 'num_worker': 12, 'batch_size': 12, 'batch_size_val': None, 'batch_size_test': None, 'epoch': 200, 'eval_epoch': 100, 'clip_grad': None, 'sync_bn': False, 'enable_amp': True, 'amp_dtype': 'float16', 'empty_cache': False, 'empty_cache_per_epoch': False, 'find_unused_parameters': False, 'enable_wandb': True, 'wandb_project': 'AGILE3D', 'wandb_key': None, 'mix_prob': 0.0, 'param_dicts': None, 'semantic_ignore_label': -1, 'instance_ignore_label': -1, 'semantic_background_label': (0, 1), 'hooks': [{'type': 'CheckpointLoader'}, {'type': 'IterationTimer', 'warmup_iter': 2}, {'type': 'InformationWriter'}, {'type': 'ISegEvaluator', 'semantic_ignore': -1, 'instance_ignore': -1, 'semantic_background': (0, 1)}, {'type': 'CheckpointSaver', 'save_freq': 10}, {'type': 'PreciseEvaluator', 'test_last': False}], 'train': {'type': 'InsSegTrainer'}, 'test': {'type': 'InsSegTesterUser'}, 'num_classes': 20, 'class_names': ['wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refridgerator', 'shower curtain', 'toilet', 'sink', 'bathtub', 'otherfurniture'], 'semantic_ignore': -1, 'instance_ignore': -1, 'semantic_background': (0, 1), 'matcher_cfg': {'cost_class': 1.0, 'cost_focal': 2.0, 'cost_dice': 2.0, 'instance_ignore': -1}, 'model': {'type': 'Agile3d-v1m1', 'pcd_backbone': {'type': 'SpUNet-v1m1-fpn', 'in_channels': 6, 'num_classes': 0, 'channels': (32, 64, 128, 256, 256, 128, 96, 96), 'layers': (2, 3, 4, 6, 2, 2, 2, 2)}, 'mask_decoder': {'type': 'Agile3dMaskDecoder', 'transformer_block_cfg': {'type': 'Mask3dDecoderBlock', 'embedding_dim': 128, 'num_heads': 8, 'mlp_dim': 1024, 'activation': 'relu', 'attn_drop': 0.0, 'layer_drop': 0.0, 'norm_before': False}, 'num_classes': 20, 'attn_mask_types': ['float', 'bool', 'bool', 'bool', 'bool'], 'enable_final_block': True, 'num_decoders': 3, 'shared_decoder': True, 'mask_num': 1}, 'loss': {'type': 'InsSegLoss', 'cls_loss_cfg': [{'type': 'CrossEntropyLoss', 'loss_weight': 1.0, 'reduction': 'mean', 'ignore_index': -1}], 'mask_loss_cfg': [{'type': 'BinaryCrossEntropyLoss', 'reduction': 'mean', 'logits': True, 'loss_weight': 2.0}, {'type': 'BinaryDiceLoss', 'exponent': 1, 'reduction': 'mean', 'logits': True, 'loss_weight': 2.0}]}, 'fused_backbone': False, 'on_segment': False, 'matcher_cfg': {'cost_class': 1.0, 'cost_focal': 2.0, 'cost_dice': 2.0, 'instance_ignore': -1}, 'aux': True, 'features_dims': (256, 256, 128, 96, 96), 'num_query': 100, 'query_type': 'sample', 'mask_threshold': 0.5, 'topk_per_scene': 200, 'semantic_ignore': -1, 'instance_ignore': -1, 'semantic_background': (0, 1)}, 'optimizer': {'type': 'AdamW', 'lr': 0.001, 'weight_decay': 0.0001}, 'scheduler': {'type': 'OneCycleLR', 'max_lr': 0.001, 'pct_start': 0.5, 'anneal_strategy': 'cos', 'div_factor': 10.0, 'final_div_factor': 1.0}, 'dataset_type': 'ScanNetDataset', 'data_root': 'data/scannet', 'data': {'num_classes': 20, 'ignore_index': -1, 'names': ['wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refridgerator', 'shower curtain', 'toilet', 'sink', 'bathtub', 'otherfurniture'], 'ext_valid_assets': ['sampled_idx_fps_100'], 'train': {'type': 'ScanNetDataset', 'split': 'train', 'data_root': 'data/scannet', 'transform': [{'type': 'Copy', 'keys_dict': {'sampled_idx_fps_100': 'sampled_index'}}, {'type': 'CenterShift', 'apply_z': True}, {'type': 'RandomDropout', 'dropout_ratio': 0.2, 'dropout_application_ratio': 0.2}, {'type': 'RandomRotate', 'angle': [-1, 1], 'axis': 'z', 'center': [0, 0, 0], 'p': 0.5}, {'type': 'RandomRotate', 'angle': [-0.015625, 0.015625], 'axis': 'x', 'p': 0.5}, {'type': 'RandomRotate', 'angle': [-0.015625, 0.015625], 'axis': 'y', 'p': 0.5}, {'type': 'RandomScale', 'scale': [0.9, 1.1]}, {'type': 'RandomFlip', 'p': 0.5}, {'type': 'RandomJitter', 'sigma': 0.005, 'clip': 0.02}, {'type': 'ElasticDistortion', 'distortion_params': [[0.2, 0.4], [0.8, 1.6]]}, {'type': 'ChromaticAutoContrast', 'p': 0.2, 'blend_factor': None}, {'type': 'ChromaticTranslation', 'p': 0.95, 'ratio': 0.05}, {'type': 'ChromaticJitter', 'p': 0.95, 'std': 0.05}, {'type': 'GridSample', 'grid_size': 0.02, 'hash_type': 'fnv', 'mode': 'train', 'return_grid_coord': True}, {'type': 'SampledIndex2Mask'}, {'type': 'SphereCrop', 'point_max': 102400, 'mode': 'random'}, {'type': 'CenterShift', 'apply_z': False}, {'type': 'NormalizeColor'}, {'type': 'InstanceParser', 'segment_ignore_index': (-1, 0, 1), 'instance_ignore_index': -1}, {'type': 'ToTensor'}, {'type': 'Collect', 'keys': ('coord', 'grid_coord', 'segment', 'instance', 'sampled_mask'), 'feat_keys': ('color', 'normal')}], 'test_mode': False, 'loop': 2}, 'val': {'type': 'ScanNetDataset', 'split': 'val', 'data_root': 'data/scannet', 'transform': [{'type': 'Copy', 'keys_dict': {'sampled_idx_fps_100': 'sampled_index'}}, {'type': 'CenterShift', 'apply_z': True}, {'type': 'GridSample', 'grid_size': 0.02, 'hash_type': 'fnv', 'mode': 'train', 'return_grid_coord': True}, {'type': 'SampledIndex2Mask'}, {'type': 'CenterShift', 'apply_z': False}, {'type': 'NormalizeColor'}, {'type': 'InstanceParser', 'segment_ignore_index': (-1, 0, 1), 'instance_ignore_index': -1}, {'type': 'ToTensor'}, {'type': 'Collect', 'keys': ('coord', 'grid_coord', 'segment', 'instance', 'sampled_mask'), 'feat_keys': ('color', 'normal')}], 'test_mode': False}, 'test': {'type': 'ScanNetDataset', 'split': 'val', 'data_root': 'data/scannet', 'transform': [{'type': 'Copy', 'keys_dict': {'sampled_idx_fps_100': 'sampled_index'}}, {'type': 'CenterShift', 'apply_z': True}, {'type': 'NormalizeColor'}], 'test_mode': True, 'test_cfg': {'voxelize': {'type': 'GridSample', 'grid_size': 0.02, 'hash_type': 'fnv', 'mode': 'train', 'return_grid_coord': True, 'return_inverse': True}, 'crop': None, 'post_transform': [{'type': 'SampledIndex2Mask'}, {'type': 'CenterShift', 'apply_z': False}, {'type': 'InstanceParser', 'segment_ignore_index': (-1, 0, 1), 'instance_ignore_index': -1}, {'type': 'ToTensor'}, {'type': 'Collect', 'keys': ('coord', 'grid_coord', 'inverse', 'segment', 'instance', 'sampled_mask'), 'feat_keys': ('color', 'normal')}], 'aug_transform': [[{'type': 'RandomFlip', 'p': 1}]]}}}, 'num_worker_per_gpu': 12, 'batch_size_per_gpu': 12, 'batch_size_val_per_gpu': 1, 'batch_size_test_per_gpu': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = default_config_parser(args.config_file, args.options)\n",
    "cfg = default_setup(cfg)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. dataset\n",
    "构建 dataset, 可以使用固有的方法, 加载 data_root 中的数据, 还没做 transform\n",
    "- 见 `pointcept/datasets/defaults.py: DefaultDataset.get_data()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-19 05:05:42,333 INFO defaults.py line 70 2172258] Totally 1201 x 2 samples in scannet train set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['normal', 'sampled_idx_fps_100', 'coord', 'color', 'name', 'split', 'segment', 'instance'])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = build_dataset_iseg(cfg.data.train, ext_valid_assets=cfg.data.ext_valid_assets)\n",
    "data_dict = train_dataset.get_data(0)\n",
    "print(data_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. train dataloader\n",
    "加载经过 transform 的数据\n",
    "- 见 `pointcept/datasets/defaults.py: DefaultDataset.__getitem__()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['coord', 'grid_coord', 'segment', 'instance', 'offset', 'feat'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=3,\n",
    "            shuffle=False,\n",
    "            num_workers=1,\n",
    "            sampler=None,\n",
    "            collate_fn=collate_fn_iseg,\n",
    "            pin_memory=True,\n",
    "            worker_init_fn=None,\n",
    "            drop_last=True,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "data_iterator = enumerate(train_loader)\n",
    "for idx, input_dict in data_iterator:\n",
    "    break\n",
    "input_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. test dataloader\n",
    "与 train 和 val 下的略有不同\n",
    "- 见 `pointcept/datasets/defaults.py: DefaultDataset.prepare_test_data()`\n",
    "- 会把各种 grid sampling 的 fragment 结果都收集起来\n",
    "- TODO 现在跟 InstanceParser 有冲突，因为 instance parser 在 post_transform 中，所以暂时只用 train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-19 05:15:14,771 INFO defaults.py line 70 2172258] Totally 312 x 1 samples in scannet val set.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/data/ext_workspace/yuzijian2/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/data/ext_workspace/yuzijian2/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/data/ext_workspace/yuzijian2/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/data/shared_workspace/yuzijian/ws/ISeg3D/pointcept/datasets/defaults.py\", line 187, in __getitem__\n    return self.prepare_test_data(idx)\n  File \"/data/shared_workspace/yuzijian/ws/ISeg3D/pointcept/datasets/defaults.py\", line 169, in prepare_test_data\n    data_part_list = self.test_voxelize(data)\n  File \"/data/shared_workspace/yuzijian/ws/ISeg3D/pointcept/datasets/transform.py\", line 842, in __call__\n    mask = np.zeros_like(data_dict[\"segment\"]).astype(bool)\nKeyError: 'segment'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/data/shared_workspace/yuzijian/ws/ISeg3D/example/datasets/data_loader.ipynb 单元格 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blinke10-2/data/shared_workspace/yuzijian/ws/ISeg3D/example/datasets/data_loader.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m test_loader \u001b[39m=\u001b[39m test_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blinke10-2/data/shared_workspace/yuzijian/ws/ISeg3D/example/datasets/data_loader.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m             test_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blinke10-2/data/shared_workspace/yuzijian/ws/ISeg3D/example/datasets/data_loader.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m             batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinke10-2/data/shared_workspace/yuzijian/ws/ISeg3D/example/datasets/data_loader.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m             collate_fn\u001b[39m=\u001b[39mbase_collate_fn,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinke10-2/data/shared_workspace/yuzijian/ws/ISeg3D/example/datasets/data_loader.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinke10-2/data/shared_workspace/yuzijian/ws/ISeg3D/example/datasets/data_loader.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m data_iterator \u001b[39m=\u001b[39m \u001b[39menumerate\u001b[39m(test_loader)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blinke10-2/data/shared_workspace/yuzijian/ws/ISeg3D/example/datasets/data_loader.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, input_dict \u001b[39min\u001b[39;00m data_iterator:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinke10-2/data/shared_workspace/yuzijian/ws/ISeg3D/example/datasets/data_loader.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinke10-2/data/shared_workspace/yuzijian/ws/ISeg3D/example/datasets/data_loader.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m input_dict[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mkeys(), input_dict[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mfragment_list\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mkeys()\n",
      "File \u001b[0;32m~/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/data/ext_workspace/yuzijian2/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/data/ext_workspace/yuzijian2/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/data/ext_workspace/yuzijian2/.conda/envs/iseg3d_ptv3_2/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/data/shared_workspace/yuzijian/ws/ISeg3D/pointcept/datasets/defaults.py\", line 187, in __getitem__\n    return self.prepare_test_data(idx)\n  File \"/data/shared_workspace/yuzijian/ws/ISeg3D/pointcept/datasets/defaults.py\", line 169, in prepare_test_data\n    data_part_list = self.test_voxelize(data)\n  File \"/data/shared_workspace/yuzijian/ws/ISeg3D/pointcept/datasets/transform.py\", line 842, in __call__\n    mask = np.zeros_like(data_dict[\"segment\"]).astype(bool)\nKeyError: 'segment'\n"
     ]
    }
   ],
   "source": [
    "test_dataset = build_dataset_iseg(cfg.data.test, ext_valid_assets=cfg.data.ext_valid_assets)\n",
    "def base_collate_fn(batch):\n",
    "    return batch\n",
    "test_loader = test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            num_workers=1,\n",
    "            pin_memory=True,\n",
    "            sampler=None,\n",
    "            collate_fn=base_collate_fn,\n",
    "        )\n",
    "data_iterator = enumerate(test_loader)\n",
    "for idx, input_dict in data_iterator:\n",
    "    break\n",
    "input_dict[0].keys(), input_dict[0][\"fragment_list\"][0].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iseg3d_ptv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
